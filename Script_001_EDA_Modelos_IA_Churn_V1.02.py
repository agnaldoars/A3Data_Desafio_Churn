# ‚úÖ Modelos de Avalia√ß√£o e Compara√ß√£o - Cross Validation:
# Models
# * RandomForest
#    Ensemble de √Årvores de Decis√£o (supervisionado)
#    Robusto, evita overfitting, lida bem com dados mistos
# *  LogisticRegression
#    Regress√£o linear para classifica√ß√£o bin√°ria
# 	Interpreta√ß√£o simples e r√°pida, baseline eficaz
# * XGBoos
#   Gradient Boosting com regulariza√ß√£o	Alta performance,
#   controle fino do aprendizado

# üõ†Ô∏è Etapas:
# Pr√©-processamento com get_dummies()
# Aplica√ß√£o de valida√ß√£o cruzada (StratifiedKFold)
# Avalia√ß√£o com f1-score (porque o problema √© desequilibrado, muitos No e pouco Yes ou 0/1)
# Utiliza√ß√£o de melhores hiperpar√¢metros/recomendados

import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import make_scorer, f1_score
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
import warnings
import plotly.express as px

warnings.filterwarnings("ignore")
#
# Base tratada........
df = pd.read_csv("Customer_Churn_Customer_Churn.csv")

# Remover espa√ßos em branco nas colunas
df.columns = df.columns.str.strip()
# Vari√°vel Est√° com Valores Categoricos
# Convers√£o da vari√°vel alvo para bin√°ria --- na proxima
# df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})


# Substituir v√≠rgulas por pontos nas colunas num√©ricas e converter para float
df["MonthlyCharges"] = (
    df["MonthlyCharges"].astype(str).str.replace(",", ".").astype(float)
)
df["TotalCharges"] = (
    df["TotalCharges"]
    .astype(str)
    .str.replace(",", ".")
    .replace(" ", pd.NA)
    .astype(float)
)

# Remover linhas com valores ausentes
df.dropna(inplace=True)

# 1. Pr√©-processamento
df_encoded = pd.get_dummies(df.drop(columns=["customerID"]), drop_first=True)
df_encoded.columns
# Separar features e target
X = df_encoded.drop(
    columns="Churn_Yes"
)  # target bin√°rio(Yes/No) virou coluna com get_dummies
y = df_encoded["Churn_Yes"]

# 2. Valida√ß√£o cruzada estratificada
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
f1 = make_scorer(f1_score)

# 3. Modelos com hiperpar√¢metros recomendados
modelos = {
    "RandomForest": RandomForestClassifier(
        n_estimators=200,
        max_depth=10,
        min_samples_split=10,
        class_weight="balanced",
        random_state=42,
    ),
    "LogisticRegression": LogisticRegression(
        solver="liblinear", C=1.0, class_weight="balanced", random_state=42
    ),
    "XGBoost": XGBClassifier(
        n_estimators=150,
        max_depth=4,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        use_label_encoder=False,
        eval_metric="logloss",
        scale_pos_weight=2,  # importante para classes desbalanceadas
        random_state=42,
    ),
}

# 4. Avaliar modelos
for nome, modelo in modelos.items():
    scores = cross_val_score(modelo, X, y, cv=cv, scoring=f1)
    print(
        f"{nome}: F1-score m√©dio = {scores.mean():.4f} | Desvio padr√£o = {scores.std():.4f}"
    )

# RandomForest: F1-score m√©dio = 0.6382 | Desvio padr√£o = 0.0091
# LogisticRegression: F1-score m√©dio = 0.6291 | Desvio padr√£o = 0.0063
# XGBoost: F1-score m√©dio = 0.6287 | Desvio padr√£o = 0.0121

# Dados dos modelos
dados_modelos = pd.DataFrame(
    {
        "Modelo": ["RandomForest", "LogisticRegression", "XGBoost"],
        "F1_score_medio": [0.6382, 0.6291, 0.6287],
        "Desvio_padrao": [0.0091, 0.0063, 0.0121],
    }
)

# Gr√°fico de barras (desvio padr√£o)
fig = px.bar(
    dados_modelos,
    x="Modelo",
    y="F1_score_medio",
    error_y="Desvio_padrao",
    title="Compara√ß√£o de Modelos - F1-score M√©dio",
    labels={"F1_score_medio": "F1-score M√©dio"},
    text=dados_modelos["F1_score_medio"].round(4),
    color="Modelo",
)

fig.update_traces(textposition="outside")
fig.update_layout(yaxis=dict(title="F1-score", range=[0.60, 0.65]))
fig.show()


# üìä F1 Score
# Combina precis√£o e recall.
# Ideal para problemas desequilibrados,
# como Churn, onde errar a classe minorit√°ria
# (quem cancela) custa caro.
#
# Um F1-score de 0.63 indica desempenho intermedi√°rio ‚Äî
# o modelo acerta boa parte dos casos, mas ainda h√°
# espa√ßo para melhorar a detec√ß√£o dos clientes que v√£o
# cancelar.
#
# üìå Justificativa gerencial por modelo:
# üî∑ 1. RandomForest ‚Äì F1: 0.6382
# ‚úÖ Melhor desempenho geral entre os tr√™s.
#
# ‚úÖ √â um modelo robusto, funciona bem com dados mistos e sem muitos ajustes.
#
# üìä Boa escolha para implantar rapidamente com confian√ßa e estabilidade.
#
# üîÑ F√°cil de explicar para times de neg√≥cio usando import√¢ncia de vari√°veis.
#
# Indicado para produ√ß√£o, a menos que haja limita√ß√µes de processamento.
#
# üî∂ 2. LogisticRegression ‚Äì F1: 0.6291
# ‚öñÔ∏è Quase o mesmo desempenho que RandomForest.
#
# ‚úÖ Mais simples, mais r√°pido e mais interpret√°vel.
#
# üìà Ideal para cen√°rios com pouca infraestrutura, ou onde a explica√ß√£o clara do modelo √© essencial.
#
# üß† Pode ser √∫til como modelo base de compara√ß√£o, ou para an√°lises explorat√≥rias.
#
# üî∏ 3. XGBoost ‚Äì F1: 0.6287
# ‚öôÔ∏è Modelo de alta performance, √≥timo para tunar em problemas complexos.
#
# ü§è Mais inst√°vel (maior desvio padr√£o) ‚Äî precisa de ajustes finos (hyperparameter tuning).
#
# üíª Recomendado quando se busca m√°ximo desempenho e h√° recursos computacionais dispon√≠veis.
#
# Por ora, seu desempenho n√£o superou os outros ‚Äî talvez por precisar de mais ajustes.
#
# ‚úÖ Conclus√£o gerencial:
# Random Forest √© o modelo com o melhor equil√≠brio entre desempenho e estabilidade, sendo recomendado para uso imediato ou piloto.
# Logistic Regression √© uma boa alternativa quando h√° foco em simplicidade, transpar√™ncia e custo computacional baixo.
# XGBoost, embora poderoso, ainda n√£o superou os outros ‚Äî vale a pena explorar ajustes para ver se ele pode render mais.

# from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, StratifiedKFold

# Grade de hiperpar√¢metros
param_grid = {
    "n_estimators": [100, 200],
    "max_depth": [5, 10, None],
    "min_samples_split": [2, 5, 10],
    "class_weight": ["balanced"],
}

# Modelo base
rf = RandomForestClassifier(random_state=42)

# Valida√ß√£o estratificada
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# GridSearchCV
grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    scoring="f1",
    cv=cv,
    n_jobs=-1,  # usa todos os n√∫cleos dispon√≠veis
    verbose=1,
)

# Rodar busca
grid_search.fit(X, y)

# Resultados
print("Melhor F1-score:", grid_search.best_score_)
print("Melhores hiperpar√¢metros:", grid_search.best_params_)
# Melhor F1-score: 0.63824195126777
# Melhores hiperpar√¢metros: {'class_weight': 'balanced',
#                               'max_depth': 10,
#                       'min_samples_split': 10,
#                            'n_estimators': 200}
